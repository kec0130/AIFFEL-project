{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 개념\n",
    "## 1. Encoding & Decoding\n",
    "인공지능 모델에는 0과 1의 비트로 표현 가능한 숫자 매트릭스만 입력할 수 있다. 따라서 텍스트 데이터를 입력하려면 단어에 숫자를 맵핑한 단어 사전을 만들고, 단어에서 숫자로 encode, 숫자에서 단어로 decode할 수 있도록 만들주어야 한다. 아래 예제에서는 'i feel hungry', 'i eat lunch', 'now i feel happy'라는 3개의 간단한 문장의 단어들을 숫자로 표현하는 예시를 들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리로 단어 사전 만들기\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다.\n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다.\n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)   # {인덱스:단어} 구조의 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리를 {단어:인덱스} 구조로 바꾸기\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)\n",
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다.\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다.\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']가 아래와 같이 변환됩니다.\n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반대로, 숫자 벡터로 encode된 문장을 원래 텍스트로 decode하는 함수입니다.\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  # [1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다.\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding 레이어\n",
    "단순히 텍스트를 숫자로 바꾼 데이터는 인공지능 모델의 입력으로 사용하기엔 어딘가 부족하다. 단어의 의미를 나타내는 벡터를 만들어 훈련 가능한 파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화할 수 있어야 한다. 이러한 의미벡터 파라미터를 구현한 것을 Embedding 레이어라고 한다. 이제 Lookup Table형태로 구성된 Embedding 레이어를 활용하여 이전 스텝의 텍스트 데이터를 워드벡터 텐서 형태로 다시 표현해볼 것이다. 이때 유의할 점은, Embedding 레이어의 인풋이 되는 문장 벡터의 길이가 일정해야 한다는 것이다. 문장 벡터 뒤에 0으로 된 패딩을 추가하여 길이를 맞춰주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00020378  0.04945518 -0.00241227 -0.04970206]\n",
      "  [-0.01249854  0.0344717  -0.02991942 -0.03701938]\n",
      "  [ 0.01386991 -0.00677185 -0.04424417  0.00175039]\n",
      "  [ 0.00109487 -0.02515228 -0.0207739   0.02250204]\n",
      "  [ 0.01643622 -0.00020786 -0.0480121  -0.04729075]]\n",
      "\n",
      " [[ 0.00020378  0.04945518 -0.00241227 -0.04970206]\n",
      "  [-0.01249854  0.0344717  -0.02991942 -0.03701938]\n",
      "  [ 0.01784482  0.0177759  -0.04394634 -0.01088767]\n",
      "  [-0.00737165  0.01219853  0.01969201 -0.02328545]\n",
      "  [ 0.01643622 -0.00020786 -0.0480121  -0.04729075]]\n",
      "\n",
      " [[ 0.00020378  0.04945518 -0.00241227 -0.04970206]\n",
      "  [-0.01099447 -0.00561415 -0.01435689 -0.01650896]\n",
      "  [-0.01249854  0.0344717  -0.02991942 -0.03701938]\n",
      "  [ 0.01386991 -0.00677185 -0.04424417  0.00175039]\n",
      "  [-0.00969218 -0.011184   -0.04079904  0.04317199]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 4차원의 워드벡터를 가정 (변경 가능)\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# padding으로 word vector의 길이 맞추기\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)   # shape에서 3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드벡터의 차원수를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 모델\n",
    "### 3-1. RNN\n",
    "Recurrent Neural Netowrk(RNN)은 텍스트 데이터를 다루는데 주로 사용되는 딥러닝 모델이다. RNN은 시퀀스(Sequence) 형태의 데이터 처리에 최적인 모델로, 이전 시점의 모든 입력의 정보가 현재 상태에 반영되는 state machine으로 설계되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "\n",
    "# 가장 널리 쓰이는 RNN인 LSTM 레이어로 모델 설계\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # LSTM state 벡터의 차원수 (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. CNN\n",
    "텍스트 처리에 1-D Convolutional Neural Network(1-D CNN)을 사용할 수도 있다. 1-D CNN은 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식이다. GlobalMaxPooling1D() 레이어 하나만 사용하는 방법도 있으며, 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 긍정/부정을 평가하는 방식이다. CNN 계열 모델은 RNN 계열 모델보다 병렬처리가 효율적이기 때문에 학습속도가 훨씬 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "\n",
    "# 1-D CNN 모델 설계\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "\n",
    "# GlobalMaxPooling1D() 레이어 하나만 사용\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 1-D CNN과 RNN 레이어를 섞어 쓰거나, FFN(FeedForward Network) 레이어만으로 구성하거나, 혹은 최근 각광받고 있는 Transformer 레이어 등 다양한 방법으로 모델을 구성할 수 있다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 영화리뷰 감성분석\n",
    "## 1. IMDB 데이터셋 분석\n",
    "### 1-1. 데이터 준비 및 확인\n",
    "IMDB Large Movie Dataset은 50000개의 영화 리뷰 텍스트로 구성되어 있으며, 긍정은 1, 부정은 0의 라벨이 달려 있다. 50000개의 리뷰를 반으로 나눠 훈련용 데이터와 테스트용 데이터를 각각 25000개씩 사용하도록 지정되어 있다. IMDB 데이터셋은 이미 숫자로 encode된 데이터이므로 encode에 사용한 딕셔너리까지 함께 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)  # 단어사전에 등재할 단어 개수 지정\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 단어사전 확인 및 가공\n",
    "word_to_index는 단어 출현 빈도를 기준으로 내림차순으로 정렬되어 있다. 실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3개씩 뒤로 밀려있어 보정이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 단어사전 확인\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])      # 'the' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# index를 3씩 뒤로 밀기\n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 4개 인덱스는 사전에 정의된 것으로 추가\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "# 변경된 인덱스 확인\n",
    "print(index_to_word[1])      # '<BOS>' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 4 가 출력됩니다.\n",
    "print(index_to_word[4])      # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# decode한 문장과 라벨을 비교하여 일치하는지 확인\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. 모델 구성을 위한 데이터 분석 및 가공\n",
    "데이터를 모델에 입력하려면 pad_sequences를 통해 문장의 길이를 통일해주어야 한다. 이때 문장 최대 길이 maxlen의 값이 전체 모델 성능에 영향을 미치기 때문에, 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋다. 그리고 padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느 쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다. RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 된다. 따라서 마지막 입력이 무의미한 padding으로 채워지는 'post'에 비해 'pre' 방식이 10% 이상 좋은 테스트 성능을 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트 생성\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균, 최대값, 표준편차 계산\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예시) 최대 길이를 (평균 + 2*표준편차)로 계산\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# padding으로 문장 길이 맞추기\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                       value=word_to_index[\"<PAD>\"],\n",
    "                                       padding='post', # 혹은 'pre'\n",
    "                                       maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                       value=word_to_index[\"<PAD>\"],\n",
    "                                       padding='post', # 혹은 'pre'\n",
    "                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델 설계와 훈련\n",
    "### 2-1. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 데이터셋 25000건 중 10000건을 분리하여 validation set으로 사용\n",
    "x_val = x_train[:10000]  \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건은 train set\n",
    "partial_x_train = x_train[10000:] \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 0.6931 - accuracy: 0.5025 - val_loss: 0.6929 - val_accuracy: 0.5055\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.6928 - accuracy: 0.5097 - val_loss: 0.6929 - val_accuracy: 0.5015\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 0.6917 - accuracy: 0.5097 - val_loss: 0.6922 - val_accuracy: 0.5016\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6877 - accuracy: 0.5150 - val_loss: 0.6914 - val_accuracy: 0.5082\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6823 - accuracy: 0.5358 - val_loss: 0.6898 - val_accuracy: 0.5086\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6790 - accuracy: 0.5285 - val_loss: 0.6897 - val_accuracy: 0.5063\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.6754 - accuracy: 0.5309 - val_loss: 0.6893 - val_accuracy: 0.5081\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6726 - accuracy: 0.5340 - val_loss: 0.6909 - val_accuracy: 0.5094\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6707 - accuracy: 0.5370 - val_loss: 0.6940 - val_accuracy: 0.5097\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6696 - accuracy: 0.5384 - val_loss: 0.6935 - val_accuracy: 0.5119\n"
     ]
    }
   ],
   "source": [
    "# model 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "            \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=epochs,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.6935 - accuracy: 0.5153\n",
      "[0.6935115456581116, 0.5153200030326843]\n"
     ]
    }
   ],
   "source": [
    "# test set으로 model 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Loss, Accuracy 그래프 시각화\n",
    "앞선 model.fit() 과정에서 train/validation loss, accuracy 등의 값이 매 epoch마다 history 변수에 저장된다. 이 데이터를 그래프로 그려보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정해 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# history 변수에 저장된 항목 확인\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')  # \"bo\"는 \"파란색 점\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')  # \"b\"는 \"파란 실선\"\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word2Vec의 적용\n",
    "### 3-1. 학습된 Embedding 레이어 분석\n",
    "단어의 특성을 저차원 벡터값으로 표현하는 워드 임베딩(word embedding) 기법은 머신러닝 기반 감성분석의 비용을 절감하면서 정확도를 크게 향상시킬 수 있는 자연어처리 기법이다. 앞서 훈련 단계에서 사용했던 model의 첫번째 레이어 역시 Embedding 레이어였다. Embedding 레이어에 학습된 워드 벡터가 유의미하게 잘 학습되었는지 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 레이어 차원 확인\n",
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(특수문자 4개는 제외)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05793155,  0.00795009,  0.02432142,  0.00115768, -0.03043961,\n",
       "        0.02092083, -0.03100175, -0.03629588, -0.00960938, -0.03866996,\n",
       "        0.00562813, -0.04734397,  0.0231584 , -0.03359229,  0.03572191,\n",
       "       -0.00967905], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "# 파일에 기록된 임베딩 파라미터를 읽어서 word vector로 활용\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fantastic', 0.8723728060722351),\n",
       " ('appeal', 0.8453997373580933),\n",
       " ('bogart', 0.8384788632392883),\n",
       " ('douglas', 0.8352924585342407),\n",
       " ('psychiatrist', 0.8317170143127441),\n",
       " ('butcher', 0.8286617994308472),\n",
       " ('situations', 0.8281365036964417),\n",
       " ('harsh', 0.8276877403259277),\n",
       " ('carrie', 0.810916543006897),\n",
       " ('invisible', 0.8082454204559326)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사한 단어와 그 유사도 확인\n",
    "word_vectors.similar_by_word(\"love\")  # 학습이 잘 되지 않아 별로 유사하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Word2Vec 임베딩 활용하여 성능 개선\n",
    "구글은 Word2Vec이라는 사전학습된(Pretrained) 워드 임베딩 모델을 제공하고 있다. Word2Vec은 무려 1억 개의 단어로 구성된 Google News dataset을 바탕으로 학습된 모델이다. 총 300만 개의 단어가 각각 300차원의 벡터로 표현되어 있다. 이처럼 사전에 학습된 임베딩 모델을 활용하는 것을 전이학습(Transfer Learning)이라고 한다. 광범위한 데이터를 통해 미리 학습해 놓은 정보를 본인이 만들고자 하는 모델의 피처로 활용하면 훨씬 빠르고 정확하게 학습할 수 있다. 이제 이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여 다시 학습시켜 볼 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000) # 메모리가 많이 소모되므로 가장 많이 사용되는 상위 100만개로 limit\n",
    "vector = word2vec['computer']\n",
    "vector     # 300dim의 워드 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907792091369629),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100709438323975),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547305345535278),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사한 단어와 그 유사도 확인\n",
    "word2vec.similar_by_word(\"love\")  # 학습이 잘 되어 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩 차례대로 카피\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 19s 620ms/step - loss: 0.6932 - accuracy: 0.5474 - val_loss: 0.6716 - val_accuracy: 0.6031\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 8s 274ms/step - loss: 0.6393 - accuracy: 0.6591 - val_loss: 0.6085 - val_accuracy: 0.6905\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 8s 276ms/step - loss: 0.5101 - accuracy: 0.7747 - val_loss: 0.4293 - val_accuracy: 0.8152\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 8s 283ms/step - loss: 0.3364 - accuracy: 0.8618 - val_loss: 0.3336 - val_accuracy: 0.8583\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 8s 281ms/step - loss: 0.2365 - accuracy: 0.9103 - val_loss: 0.3050 - val_accuracy: 0.8723\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 8s 276ms/step - loss: 0.1697 - accuracy: 0.9452 - val_loss: 0.3054 - val_accuracy: 0.8735\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 8s 280ms/step - loss: 0.1290 - accuracy: 0.9622 - val_loss: 0.3304 - val_accuracy: 0.8653\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 9s 292ms/step - loss: 0.1030 - accuracy: 0.9712 - val_loss: 0.3567 - val_accuracy: 0.8643\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 8s 275ms/step - loss: 0.0669 - accuracy: 0.9859 - val_loss: 0.3522 - val_accuracy: 0.8686\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 8s 276ms/step - loss: 0.0436 - accuracy: 0.9938 - val_loss: 0.3509 - val_accuracy: 0.8718\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 8s 275ms/step - loss: 0.0282 - accuracy: 0.9981 - val_loss: 0.3700 - val_accuracy: 0.8715\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 8s 275ms/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.3914 - val_accuracy: 0.8693\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.0156 - accuracy: 0.9993 - val_loss: 0.4031 - val_accuracy: 0.8730\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.0110 - accuracy: 0.9996 - val_loss: 0.4181 - val_accuracy: 0.8729\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 8s 273ms/step - loss: 0.0087 - accuracy: 0.9996 - val_loss: 0.4331 - val_accuracy: 0.8709\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 8s 277ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.4429 - val_accuracy: 0.8725\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 8s 280ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.4560 - val_accuracy: 0.8717\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.4698 - val_accuracy: 0.8716\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 8s 283ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.4765 - val_accuracy: 0.8715\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 8s 273ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.4868 - val_accuracy: 0.8719\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 9s - loss: 0.5239 - accuracy: 0.8604\n",
      "[0.5238618850708008, 0.8604000210762024]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)   # 정확도가 0.86으로 개선됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
